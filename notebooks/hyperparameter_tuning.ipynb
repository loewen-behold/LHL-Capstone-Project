{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2292ce52-7329-476a-8870-f2815d6aca62",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9d6923-bffc-4d33-beb3-0e9659112a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d08b170-61d6-4224-a2b3-abb340fec743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from src.hyperparameter_tuning import tune_hyperparameters\n",
    "from src.model_training import build_preprocessor, build_full_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a28a8c-56e4-488b-ba04-6c38de73abf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Both the initial cleaned data (df) and the modified version of the data after the Feature Analysis (df2) are included here for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "54c0b569-c3ef-4465-a3fb-9db4faa06a10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use this code in the event that it's needed\n",
    "df = pd.read_csv('data/processed_data/df_clean.csv')\n",
    "\n",
    "X = df.drop('at_risk', axis=1)\n",
    "y = df.at_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "eedc5409-48f2-444a-be6d-0ab2aee7b786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "numeric_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "preprocessor = build_preprocessor(numeric_features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "1a6e6a2f-3626-448b-98fa-3c8e6975a190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_model = build_full_pipeline(preprocessor, GaussianNB())\n",
    "nn_model = build_full_pipeline(preprocessor, MLPClassifier())\n",
    "xgb_model = build_full_pipeline(preprocessor, XGBClassifier())\n",
    "gb_model = build_full_pipeline(preprocessor, GradientBoostingClassifier())\n",
    "rf_model = build_full_pipeline(preprocessor, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736eb0e-32b6-4168-bad6-29cb802793c5",
   "metadata": {},
   "source": [
    "## XGBoost Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e75a39b-b50b-4dd7-9a04-a9fb8b35c7ec",
   "metadata": {},
   "source": [
    "### 1. Using Recall as scoring metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "284162b1-8be8-49da-a0cf-57b6dd1babe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [3, 5],\n",
    "    'model__learning_rate': [0.2, 0.3],\n",
    "    'model__scale_pos_weight': [5, 7, 9]  # Adjust based on the class imbalance\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2b3582fa-3ce0-498b-be05-78aa26eab090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost hyperparameters for Recall Score: {'model__learning_rate': 0.3, 'model__max_depth': 3, 'model__n_estimators': 100, 'model__scale_pos_weight': 9}\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters\n",
    "tuned_xgb_model = tune_hyperparameters(xgb_model, xgb_param_grid, X_train, y_train, scoring='recall')\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_xgb_params = tuned_xgb_model.best_params_\n",
    "\n",
    "# Print or use the best hyperparameters as needed\n",
    "print(\"Best XGBoost hyperparameters for Recall Score:\", best_xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0a19be61-28a2-47e0-9930-3f3bf866c7b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Models:\n",
      "                                               params  mean_test_score  \\\n",
      "23  {'model__learning_rate': 0.3, 'model__max_dept...         0.736611   \n",
      "20  {'model__learning_rate': 0.3, 'model__max_dept...         0.727700   \n",
      "5   {'model__learning_rate': 0.2, 'model__max_dept...         0.727700   \n",
      "2   {'model__learning_rate': 0.2, 'model__max_dept...         0.724759   \n",
      "1   {'model__learning_rate': 0.2, 'model__max_dept...         0.718745   \n",
      "\n",
      "    std_test_score  \n",
      "23        0.026142  \n",
      "20        0.046948  \n",
      "5         0.036450  \n",
      "2         0.043169  \n",
      "1         0.048144  \n"
     ]
    }
   ],
   "source": [
    "# Analyze grid search results\n",
    "cv_results = pd.DataFrame(tuned_xgb_model.cv_results_)\n",
    "\n",
    "# Display the top models based on mean test scores\n",
    "top_models = cv_results.sort_values(by='mean_test_score', ascending=False).head()\n",
    "print(\"Top Models:\")\n",
    "print(top_models[['params', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "# Select the best model\n",
    "best_model_xgb = tuned_xgb_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f5a1d07d-d735-48a9-8368-72efcf92d511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Accuracy: 0.9427753934191703\n",
      "Best Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1322\n",
      "           1       0.48      0.80      0.60        76\n",
      "\n",
      "    accuracy                           0.94      1398\n",
      "   macro avg       0.74      0.88      0.79      1398\n",
      "weighted avg       0.96      0.94      0.95      1398\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1257   65]\n",
      " [  15   61]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "y_pred_best = best_model_xgb.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report for the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "classification_rep_best = classification_report(y_test, y_pred_best)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "print(f\"\\nBest Model Accuracy: {accuracy_best}\")\n",
    "print(\"Best Model Classification Report:\\n\", classification_rep_best)\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9873ce-b1a8-44a9-b8b7-6324e4746524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "948c371b-997b-4199-8e8f-dbb82b943a9b",
   "metadata": {},
   "source": [
    "### 2. Using roc_auc as scoring metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5393b8a8-8c93-44ae-b552-51b4ddd9c258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameter grid for XGBoost\n",
    "xgb_param_grid2 = {\n",
    "    'model__n_estimators': [200, 300, 400],\n",
    "    'model__max_depth': [3, 4],\n",
    "    'model__learning_rate': [0.3, 0.4, 0.5],\n",
    "    'model__scale_pos_weight': [5, 7, 9]  # Adjust based on the class imbalance\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "223b73cc-4f10-4d8d-b1c4-5419d4cbd02b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost hyperparameters for ROC_AUC Score: {'model__learning_rate': 0.4, 'model__max_depth': 3, 'model__n_estimators': 300, 'model__scale_pos_weight': 9}\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters\n",
    "tuned_xgb_model_roc = tune_hyperparameters(xgb_model, xgb_param_grid2, X_train, y_train, scoring='roc_auc')\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_xgb_params_roc = tuned_xgb_model_roc.best_params_\n",
    "\n",
    "# Print or use the best hyperparameters as needed\n",
    "print(\"Best XGBoost hyperparameters for ROC_AUC Score:\", best_xgb_params_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d435f9cf-2bd6-467e-b3a4-97b85f70b95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Models:\n",
      "                                              params  mean_test_score  \\\n",
      "1  {'model__learning_rate': 0.4, 'model__max_dept...         0.941505   \n",
      "0  {'model__learning_rate': 0.35, 'model__max_dep...         0.938204   \n",
      "2  {'model__learning_rate': 0.45, 'model__max_dep...         0.933655   \n",
      "\n",
      "   std_test_score  \n",
      "1        0.008915  \n",
      "0        0.008977  \n",
      "2        0.016366  \n"
     ]
    }
   ],
   "source": [
    "# Analyze grid search results\n",
    "cv_results = pd.DataFrame(tuned_xgb_model_roc.cv_results_)\n",
    "\n",
    "# Display the top models based on mean test scores\n",
    "top_models = cv_results.sort_values(by='mean_test_score', ascending=False).head()\n",
    "print(\"Top Models:\")\n",
    "print(top_models[['params', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "# Select the best model\n",
    "best_model_xgb_roc = tuned_xgb_model_roc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "8b9d0ebb-82ad-4fcc-a804-4f24d3678770",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Accuracy: 0.9713876967095851\n",
      "Best Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1322\n",
      "           1       0.72      0.78      0.75        76\n",
      "\n",
      "    accuracy                           0.97      1398\n",
      "   macro avg       0.85      0.88      0.87      1398\n",
      "weighted avg       0.97      0.97      0.97      1398\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1299   23]\n",
      " [  17   59]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "y_pred_best_roc = best_model_xgb_roc.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report for the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best_roc)\n",
    "classification_rep_best = classification_report(y_test, y_pred_best_roc)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best_roc)\n",
    "\n",
    "print(f\"\\nBest Model Accuracy: {accuracy_best}\")\n",
    "print(\"Best Model Classification Report:\\n\", classification_rep_best)\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a76d5a-9510-48e4-a9b3-a9b5b526a474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3d29d71-b7f3-4119-9faa-47b5cbb770dd",
   "metadata": {},
   "source": [
    "### Saving the best XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f73bbf-6670-4aa2-9520-3c49c6a7edb4",
   "metadata": {},
   "source": [
    "While the best model for recall on the under-represented class is from the tuning with 'recall' as our scoring metric, the overall best model for all-around metrics is the tuned model with 'roc-auc' as our scoring metric.  Although we want the at-risk students to be correctly identified, and as many of them identified as possible, we don't want it to come at the cost of mis-classifying students who are not at risk as at-risk.  Thus, the second model is better at finding this balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c0e07e45-89fb-46a6-8ddd-3989690cdd44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/best_xgb_params_roc.pkl']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the models and their best parameters\n",
    "joblib.dump(best_model_xgb, 'models/best_model_xgb.pkl')\n",
    "joblib.dump(best_xgb_params, 'models/best_xgb_params.pkl')\n",
    "\n",
    "joblib.dump(best_model_xgb_roc, 'models/best_model_xgb_roc.pkl')\n",
    "joblib.dump(best_xgb_params_roc, 'models/best_xgb_params_roc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24036ce0-9da8-4feb-a0a7-8efd528c763f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c56641e7-2614-41f9-9200-d8f3af6cf818",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Naive Bayes Tuning\n",
    "- There is not much tuning to do for NB, but we'll make some changes to the \"priors\" parameter to see if we can come up with even a slightly improved model from the one before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "42b8e859-4b1d-4fd6-9c9f-e6b5580bb5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for Gaussian Naive Bayes\n",
    "nb_param_grid = {\n",
    "    'model__priors': [None, [0.1, 0.9], [0.2, 0.8], [0.3, 0.7], [0.4, 0.6], [0.5, 0.5], [0.6, 0.4], [0.7, 0.3], [0.8, 0.2], [0.9, 0.1]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "31cbd628-6a00-44b0-a111-edf38475ed4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Naive Bayes hyperparameters for ROC_AUC Score: {'model__priors': None}\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters\n",
    "tuned_nb_model_roc = tune_hyperparameters(nb_model, nb_param_grid, X_train, y_train, scoring='roc_auc')\n",
    "\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_nb_params_roc = tuned_nb_model_roc.best_params_\n",
    "\n",
    "\n",
    "# Print or use the best hyperparameters as needed\n",
    "print(\"Best Naive Bayes hyperparameters for ROC_AUC Score:\", best_nb_params_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "bae6b6d8-376c-475d-8d84-d83f6bb10c1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Models:\n",
      "                          params  mean_test_score  std_test_score\n",
      "0        {'model__priors': None}         0.699506        0.013018\n",
      "1  {'model__priors': [0.1, 0.9]}         0.699506        0.013018\n",
      "2  {'model__priors': [0.2, 0.8]}         0.699506        0.013018\n",
      "3  {'model__priors': [0.3, 0.7]}         0.699506        0.013018\n",
      "4  {'model__priors': [0.4, 0.6]}         0.699506        0.013018\n"
     ]
    }
   ],
   "source": [
    "# Analyze grid search results\n",
    "cv_results = pd.DataFrame(tuned_nb_model_roc.cv_results_)\n",
    "\n",
    "# Display the top models based on mean test scores\n",
    "top_models = cv_results.sort_values(by='mean_test_score', ascending=False).head()\n",
    "print(\"Top Models:\")\n",
    "print(top_models[['params', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "# Select the best model\n",
    "best_model = tuned_nb_model_roc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "0e81cbbd-c825-4aa6-ad12-1967c7e16c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Accuracy: 0.5565092989985694\n",
      "Best Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.54      0.70      1322\n",
      "           1       0.10      0.86      0.17        76\n",
      "\n",
      "    accuracy                           0.56      1398\n",
      "   macro avg       0.54      0.70      0.44      1398\n",
      "weighted avg       0.94      0.56      0.67      1398\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[713 609]\n",
      " [ 11  65]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report for the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "classification_rep_best = classification_report(y_test, y_pred_best)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "print(f\"\\nBest Model Accuracy: {accuracy_best}\")\n",
    "print(\"Best Model Classification Report:\\n\", classification_rep_best)\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d8ffc9-cbac-4288-bd46-e4b3c0bdc1ac",
   "metadata": {},
   "source": [
    "### Obeservations:\n",
    "- This model is no better than the one we had previously in that, it contains more false negatives.  Despite the fact that the NB model does have a substantially low accuracy (with many false positives), we used it in the ensemble meta model because of it's high recall rate for the under-represented class.\n",
    "- When we retrain the ensemble model, we will stick with the out-of-the-box NB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df48deb9-5046-4cd4-a401-011165abb4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5e00979-bacd-4f7a-ae3a-246c58bff5ab",
   "metadata": {},
   "source": [
    "## Neural Network Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c1a91e-ebac-4573-84b0-f541440d5e11",
   "metadata": {},
   "source": [
    "#### 1. Using 'roc_auc' for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f76e0adb-afc6-412c-86bb-4a36b3511823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn_param_grid = {\n",
    "    'model__hidden_layer_sizes': [(50,), (100,), (50, 50), (200,)],\n",
    "    'model__alpha': [0.01, 0.05, 0.1],\n",
    "    'model__learning_rate': ['adaptive'],\n",
    "    'model__solver': ['adam'],\n",
    "    'model__max_iter': [500, 600],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7507045e-dfd3-4a67-a574-e95cebc985d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Neural Net hyperparameters for ROC_AUC Score: {'model__alpha': 0.05, 'model__hidden_layer_sizes': (100,), 'model__learning_rate': 'adaptive', 'model__max_iter': 500, 'model__solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters\n",
    "tuned_nn_model_roc = tune_hyperparameters(nn_model, nn_param_grid, X_train, y_train, scoring='roc_auc')\n",
    "\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_nn_params_roc = tuned_nn_model_roc.best_params_\n",
    "\n",
    "\n",
    "# Print or use the best hyperparameters as needed\n",
    "print(\"Best Neural Net hyperparameters for ROC_AUC Score:\", best_nn_params_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "fd23cfbc-9308-4ef9-a124-304fdef83fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Models:\n",
      "                                              params  mean_test_score  \\\n",
      "1  {'model__alpha': 0.05, 'model__hidden_layer_si...         0.931744   \n",
      "3  {'model__alpha': 0.05, 'model__hidden_layer_si...         0.929255   \n",
      "0  {'model__alpha': 0.05, 'model__hidden_layer_si...         0.924486   \n",
      "2  {'model__alpha': 0.05, 'model__hidden_layer_si...         0.919635   \n",
      "\n",
      "   std_test_score  \n",
      "1        0.006954  \n",
      "3        0.007944  \n",
      "0        0.008172  \n",
      "2        0.010047  \n"
     ]
    }
   ],
   "source": [
    "# Analyze grid search results\n",
    "cv_results = pd.DataFrame(tuned_nn_model_roc.cv_results_)\n",
    "\n",
    "# Display the top models based on mean test scores\n",
    "top_models = cv_results.sort_values(by='mean_test_score', ascending=False).head()\n",
    "print(\"Top Models:\")\n",
    "print(top_models[['params', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "# Select the best model\n",
    "best_model_nn_roc = tuned_nn_model_roc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e4ac5291-3a57-4dd0-bf69-e494320aad47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Accuracy: 0.9670958512160229\n",
      "Best Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1322\n",
      "           1       0.78      0.55      0.65        76\n",
      "\n",
      "    accuracy                           0.97      1398\n",
      "   macro avg       0.88      0.77      0.81      1398\n",
      "weighted avg       0.96      0.97      0.96      1398\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1310   12]\n",
      " [  34   42]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "y_pred_best = best_model_nn_roc.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report for the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "classification_rep_best = classification_report(y_test, y_pred_best)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "print(f\"\\nBest Model Accuracy: {accuracy_best}\")\n",
    "print(\"Best Model Classification Report:\\n\", classification_rep_best)\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad31f7-6a46-4d42-9979-45b306fe006f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48af17e1-bd92-4e37-83c8-57846d43c364",
   "metadata": {},
   "source": [
    "#### 2. Using 'f1' for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "e1608a71-72a8-4186-aa77-425582ffbe78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn_param_grid2 = {\n",
    "    'model__hidden_layer_sizes': [(50,), (100,), (50, 50), (200,)],\n",
    "    'model__alpha': [0.01, 0.05, 0.1],\n",
    "    'model__learning_rate': ['adaptive'],\n",
    "    'model__solver': ['adam'],\n",
    "    'model__max_iter': [500, 600],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "62463dcd-9c71-4e42-8e64-7d266bc29ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Neural Net hyperparameters for F1 Score: {'model__alpha': 0.01, 'model__hidden_layer_sizes': (50,), 'model__learning_rate': 'adaptive', 'model__max_iter': 500, 'model__solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters\n",
    "tuned_nn_model_f1 = tune_hyperparameters(nn_model, nn_param_grid2, X_train, y_train, scoring='f1')\n",
    "\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_nn_params_f1 = tuned_nn_model_f1.best_params_\n",
    "\n",
    "\n",
    "# Print or use the best hyperparameters as needed\n",
    "print(\"Best Neural Net hyperparameters for F1 Score:\", best_nn_params_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "8d44e3d1-bd1d-4130-8588-948cd90307bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Models:\n",
      "                                              params  mean_test_score  \\\n",
      "1  {'model__alpha': 0.01, 'model__hidden_layer_si...         0.610509   \n",
      "0  {'model__alpha': 0.001, 'model__hidden_layer_s...         0.580973   \n",
      "\n",
      "   std_test_score  \n",
      "1        0.051827  \n",
      "0        0.061445  \n"
     ]
    }
   ],
   "source": [
    "# Analyze grid search results\n",
    "cv_results = pd.DataFrame(tuned_nn_model_f1.cv_results_)\n",
    "\n",
    "# Display the top models based on mean test scores\n",
    "top_models = cv_results.sort_values(by='mean_test_score', ascending=False).head()\n",
    "print(\"Top Models:\")\n",
    "print(top_models[['params', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "# Select the best model\n",
    "best_model_nn_f1 = tuned_nn_model_f1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "e34b4f48-b901-46fb-a3c5-c78e80c83692",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Accuracy: 0.9685264663805436\n",
      "Best Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1322\n",
      "           1       0.77      0.61      0.68        76\n",
      "\n",
      "    accuracy                           0.97      1398\n",
      "   macro avg       0.87      0.80      0.83      1398\n",
      "weighted avg       0.97      0.97      0.97      1398\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1308   14]\n",
      " [  30   46]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "y_pred_best = best_model_nn_f1.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report for the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "classification_rep_best = classification_report(y_test, y_pred_best)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "print(f\"\\nBest Model Accuracy: {accuracy_best}\")\n",
    "print(\"Best Model Classification Report:\\n\", classification_rep_best)\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8251662-35c3-4d8a-86c1-592aebb220b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "737252e8-5491-4598-a4ef-abee770a6ec6",
   "metadata": {},
   "source": [
    "### Saving the best Neural Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "76cd6f47-caae-4f24-b74f-c1d52b8f264c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/best_nn_params_f1.pkl']"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the models and their best parameters\n",
    "joblib.dump(best_model_nn_f1, 'models/best_model_nn_f1.pkl')\n",
    "joblib.dump(best_nn_params_f1, 'models/best_nn_params_f1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d7b3b3-05fa-4fcb-b4ee-361dded64191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1209ac71-b88e-48a6-93e5-6604b9314d60",
   "metadata": {},
   "source": [
    "## Random Forest Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23935cb-dff8-40dc-a264-0a8d1bc01257",
   "metadata": {},
   "source": [
    "#### 1. Using 'roc_auc' for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "80b10b9f-e94c-4c7c-83e7-f93f71fad9a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    'model__n_estimators': [400, 500, 600],\n",
    "    'model__min_samples_split': [3, 5],\n",
    "    'model__min_samples_leaf': [1, 2],\n",
    "    'model__max_features': ['sqrt'],\n",
    "    'model__class_weight': ['balanced', {0: 1, 1: 2}, {0: 1, 1: 3}, {0: 1, 1: 4}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "15e12d19-b974-44e3-a26d-6087ac4cded6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest hyperparameters for ROC_AUC Score: {'model__class_weight': {0: 1, 1: 2}, 'model__max_features': 'sqrt', 'model__min_samples_leaf': 1, 'model__min_samples_split': 3, 'model__n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters\n",
    "tuned_rf_model_roc = tune_hyperparameters(rf_model, rf_param_grid, X_train, y_train, scoring = 'roc_auc')\n",
    "\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_rf_params_roc = tuned_rf_model_roc.best_params_\n",
    "\n",
    "\n",
    "# Print or use the best hyperparameters as needed\n",
    "print(\"Best Random Forest hyperparameters for ROC_AUC Score:\", best_rf_params_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "ee7f731b-6c99-4d13-a71f-2aaa5ea6ca98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Models:\n",
      "                                               params  mean_test_score  \\\n",
      "13  {'model__class_weight': {0: 1, 1: 2}, 'model__...         0.948203   \n",
      "28  {'model__class_weight': {0: 1, 1: 3}, 'model__...         0.946693   \n",
      "1   {'model__class_weight': 'balanced', 'model__ma...         0.946017   \n",
      "15  {'model__class_weight': {0: 1, 1: 2}, 'model__...         0.945685   \n",
      "2   {'model__class_weight': 'balanced', 'model__ma...         0.945515   \n",
      "\n",
      "    std_test_score  \n",
      "13        0.003776  \n",
      "28        0.004543  \n",
      "1         0.004731  \n",
      "15        0.005345  \n",
      "2         0.004854  \n"
     ]
    }
   ],
   "source": [
    "# Analyze grid search results\n",
    "cv_results = pd.DataFrame(tuned_rf_model_roc.cv_results_)\n",
    "\n",
    "# Display the top models based on mean test scores\n",
    "top_models = cv_results.sort_values(by='mean_test_score', ascending=False).head()\n",
    "print(\"Top Models:\")\n",
    "print(top_models[['params', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "# Select the best model\n",
    "best_model_rf_roc = tuned_rf_model_roc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "179a5fe8-1e31-4928-a692-9417aa3a4779",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Accuracy: 0.9642346208869814\n",
      "Best Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1322\n",
      "           1       0.93      0.37      0.53        76\n",
      "\n",
      "    accuracy                           0.96      1398\n",
      "   macro avg       0.95      0.68      0.75      1398\n",
      "weighted avg       0.96      0.96      0.96      1398\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1320    2]\n",
      " [  48   28]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "y_pred_best = best_model_rf_roc.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report for the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "classification_rep_best = classification_report(y_test, y_pred_best)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "print(f\"\\nBest Model Accuracy: {accuracy_best}\")\n",
    "print(\"Best Model Classification Report:\\n\", classification_rep_best)\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed7810-a38f-4473-9fea-262dc91330a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "275b86ac-1fbc-4327-b3a5-afd11cd743a7",
   "metadata": {},
   "source": [
    "#### 2. Using recall score for under-represented class (pos =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "60f885e3-44c3-4cba-8053-91dc5d4efebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_param_grid2 = {\n",
    "    'model__n_estimators': [200, 300, 500],\n",
    "    'model__min_samples_split': [3],\n",
    "    'model__min_samples_leaf': [1],\n",
    "    'model__max_features': ['sqrt'],\n",
    "    'model__class_weight': ['balanced', {0: 1, 1: 2}, {0: 1, 1: 3}, {0: 1, 1: 4}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "6a8e390e-b6aa-4ec3-9745-3f25801e6309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest hyperparameters for Recall Score: {'model__class_weight': 'balanced', 'model__max_features': 'sqrt', 'model__min_samples_leaf': 1, 'model__min_samples_split': 3, 'model__n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters\n",
    "tuned_rf_model_recall = tune_hyperparameters(rf_model, rf_param_grid2, X_train, y_train, \n",
    "                                          scoring = make_scorer(recall_score, pos_label=1))\n",
    "\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_rf_params_recall = tuned_rf_model_recall.best_params_\n",
    "\n",
    "\n",
    "# Print or use the best hyperparameters as needed\n",
    "print(\"Best Random Forest hyperparameters for Recall Score:\", best_rf_params_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "b6f076b3-16cd-46b3-b923-f456f4e695b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Models:\n",
      "                                               params  mean_test_score  \\\n",
      "1   {'model__class_weight': 'balanced', 'model__ma...         0.405180   \n",
      "0   {'model__class_weight': 'balanced', 'model__ma...         0.393415   \n",
      "2   {'model__class_weight': 'balanced', 'model__ma...         0.393371   \n",
      "11  {'model__class_weight': {0: 1, 1: 4}, 'model__...         0.393284   \n",
      "9   {'model__class_weight': {0: 1, 1: 4}, 'model__...         0.390430   \n",
      "\n",
      "    std_test_score  \n",
      "1         0.062496  \n",
      "0         0.057679  \n",
      "2         0.058802  \n",
      "11        0.058147  \n",
      "9         0.062475  \n"
     ]
    }
   ],
   "source": [
    "# Analyze grid search results\n",
    "cv_results = pd.DataFrame(tuned_rf_model_recall.cv_results_)\n",
    "\n",
    "# Display the top models based on mean test scores\n",
    "top_models = cv_results.sort_values(by='mean_test_score', ascending=False).head()\n",
    "print(\"Top Models:\")\n",
    "print(top_models[['params', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "# Select the best model\n",
    "best_model_rf_recall = tuned_rf_model_recall.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "0c698769-bf94-4d61-b3d4-823e707d2cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Accuracy: 0.9613733905579399\n",
      "Best Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1322\n",
      "           1       0.82      0.37      0.51        76\n",
      "\n",
      "    accuracy                           0.96      1398\n",
      "   macro avg       0.89      0.68      0.74      1398\n",
      "weighted avg       0.96      0.96      0.95      1398\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1316    6]\n",
      " [  48   28]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "y_pred_best = best_model_rf_recall.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report for the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "classification_rep_best = classification_report(y_test, y_pred_best)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "print(f\"\\nBest Model Accuracy: {accuracy_best}\")\n",
    "print(\"Best Model Classification Report:\\n\", classification_rep_best)\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcdf806-7b21-4975-81e9-a90c81f8326b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34fad13e-1521-4e2b-88a8-db326e2902ec",
   "metadata": {},
   "source": [
    "### Saving the best Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a394d3c7-e4a7-47b7-9352-a9925dc708e5",
   "metadata": {},
   "source": [
    "In this case, we have not been able to hypertune a Random Forest Model that performs better than the out-of-box model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c45f8-bfae-4aff-a097-1efeaf4a25eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cb06ab0-f8b0-4f58-8a14-9212f406b8b8",
   "metadata": {},
   "source": [
    "## Gradient Boost Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d10773-e49a-4875-8cbd-1a3cce1f9360",
   "metadata": {},
   "source": [
    "#### 1. Using 'roc_auc' for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "4a96552d-7b78-478b-9f42-07ee0792c666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gb_param_grid = {\n",
    "    'model__n_estimators': [400, 500, 600],\n",
    "    'model__max_depth': [3, 4],\n",
    "    #'model__min_samples_split': [2, 5],\n",
    "    #'model__min_samples_leaf': [2, 3],\n",
    "    #'model__subsample': [0.8, 0.9],\n",
    "    'model__learning_rate': [0.1, 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "5f111b1a-b1eb-4a0d-b496-1c9ed9e84444",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boost hyperparameters for ROC_AUC Score: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters\n",
    "tuned_gb_model_roc = tune_hyperparameters(gb_model, gb_param_grid, X_train, y_train, scoring='roc_auc')\n",
    "\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_gb_params_roc = tuned_gb_model_roc.best_params_\n",
    "\n",
    "\n",
    "# Print or use the best hyperparameters as needed\n",
    "print(\"Best Gradient Boost hyperparameters for ROC_AUC Score:\", best_gb_params_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "010ec273-45fc-4c31-8894-34d8ffd19940",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Models:\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'model__learning_rate': 0.1, 'model__max_dept...         0.932363   \n",
      "1  {'model__learning_rate': 0.1, 'model__max_dept...         0.931222   \n",
      "2  {'model__learning_rate': 0.1, 'model__max_dept...         0.930737   \n",
      "7  {'model__learning_rate': 0.2, 'model__max_dept...         0.920476   \n",
      "4  {'model__learning_rate': 0.1, 'model__max_dept...         0.920429   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.013141  \n",
      "1        0.013914  \n",
      "2        0.013362  \n",
      "7        0.018715  \n",
      "4        0.009307  \n"
     ]
    }
   ],
   "source": [
    "# Analyze grid search results\n",
    "cv_results = pd.DataFrame(tuned_gb_model_roc.cv_results_)\n",
    "\n",
    "# Display the top models based on mean test scores\n",
    "top_models = cv_results.sort_values(by='mean_test_score', ascending=False).head()\n",
    "print(\"Top Models:\")\n",
    "print(top_models[['params', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "# Select the best model\n",
    "best_model_gb_roc = tuned_gb_model_roc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "01dd297e-f01d-4742-84b6-40317f5feb2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model Accuracy: 0.9706723891273248\n",
      "Best Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1322\n",
      "           1       0.81      0.61      0.69        76\n",
      "\n",
      "    accuracy                           0.97      1398\n",
      "   macro avg       0.89      0.80      0.84      1398\n",
      "weighted avg       0.97      0.97      0.97      1398\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1311   11]\n",
      " [  30   46]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "y_pred_best = best_model_gb_roc.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report for the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "classification_rep_best = classification_report(y_test, y_pred_best)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "print(f\"\\nBest Model Accuracy: {accuracy_best}\")\n",
    "print(\"Best Model Classification Report:\\n\", classification_rep_best)\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7602d78-1f40-421e-81ff-04769e5466ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd4543a1-6b7f-4986-a6aa-675f4f8b5374",
   "metadata": {},
   "source": [
    "### Saving the best Gradient Boost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "a9b2a063-1262-4d32-9ca3-2061f17d6e35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/best_gb_params_roc.pkl']"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the models and their best parameters\n",
    "joblib.dump(best_model_gb_roc, 'models/best_model_gb_roc.pkl')\n",
    "joblib.dump(best_gb_params_roc, 'models/best_gb_params_roc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d51bd8-f9bb-4273-a782-a8ac02b892a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
