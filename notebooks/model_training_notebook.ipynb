{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec9197ee-6260-45dc-9382-6ed176f88df7",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041219a3-929b-4e28-a90e-1e98c5608e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efcb8eda-4b3d-4d93-80f8-038f37acd40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from src.data_preprocessing import df_construct, add_eng_values, alter_term_gender\n",
    "from src.model_training import build_preprocessor, build_full_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from src.model_training import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba0c9d9c-633a-49e4-ad89-3696a6539f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "excel_file = pd.ExcelFile('data/raw_data/D2lData.xlsx')\n",
    "\n",
    "# Reading each sheet into a DataFrame\n",
    "df_d2l = pd.read_excel(excel_file, 'd2l')\n",
    "df_demo = pd.read_excel(excel_file, 'demographics')\n",
    "df_grades = pd.read_excel(excel_file, 'grades')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d4ffefa-39dc-47d3-bd89-ec3311da4083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_construct(df_d2l, df_demo, df_grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1af77621-3326-4192-9f7d-ec898d7e19d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save this cleaned dataframe to the data/processed_data folder for future use.\n",
    "df.to_csv('data/processed_data/df_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2d6ddd4-3e78-42d5-bee2-7c0fe0d48154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use this code in the event that it's needed\n",
    "# df = pd.read_csv('data/processed_data/df_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30e492c6-b447-4763-8339-f641abba6e70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop('at_risk', axis=1)\n",
    "y = df.at_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4e20734-33de-45b6-8f03-1a0737a76c07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "137ece3d-4f08-407b-bfd0-67e8d49d58cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f3fcaf7-889e-490d-bcf8-3145f8ef6908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = build_preprocessor(numeric_features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fcae86-16d8-47c4-b54b-bb1d2172285d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "697cb85d-4799-4754-bcb1-ca56e649d7cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 1: RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "600777ea-dbca-4a9e-bf3a-0e220a5dd039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_rfc = RandomForestClassifier()\n",
    "pipeline_rfc = build_full_pipeline(preprocessor, model_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c09b793a-6b55-44bb-9684-98c6993b3fde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;log_transform&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;,\n",
       "                                                                                       inverse_func=&lt;ufunc &#x27;expm1&#x27;&gt;))]),\n",
       "                                                  [&#x27;content_required&#x27;,\n",
       "                                                   &#x27;checklist_completed&#x27;,\n",
       "                                                   &#x27;discussion_post_read&#x27;,\n",
       "                                                   &#x27;number_of_assignment_submissions&#x27;,\n",
       "                                                   &#x27;total_time_sp...\n",
       "                                                   &#x27;age&#x27;, &#x27;total_course_count&#x27;,\n",
       "                                                   &#x27;course_count_by_term&#x27;,\n",
       "                                                   &#x27;completion_ratio&#x27;,\n",
       "                                                   &#x27;logins_per_course&#x27;,\n",
       "                                                   &#x27;avg_time_per_login&#x27;,\n",
       "                                                   &#x27;avg_time_by_completed_content&#x27;,\n",
       "                                                   &#x27;quiz_attempts_per_quiz&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;term&#x27;, &#x27;pseudo_course&#x27;,\n",
       "                                                   &#x27;gender&#x27;, &#x27;imm_status&#x27;])])),\n",
       "                (&#x27;model&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;log_transform&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;,\n",
       "                                                                                       inverse_func=&lt;ufunc &#x27;expm1&#x27;&gt;))]),\n",
       "                                                  [&#x27;content_required&#x27;,\n",
       "                                                   &#x27;checklist_completed&#x27;,\n",
       "                                                   &#x27;discussion_post_read&#x27;,\n",
       "                                                   &#x27;number_of_assignment_submissions&#x27;,\n",
       "                                                   &#x27;total_time_sp...\n",
       "                                                   &#x27;age&#x27;, &#x27;total_course_count&#x27;,\n",
       "                                                   &#x27;course_count_by_term&#x27;,\n",
       "                                                   &#x27;completion_ratio&#x27;,\n",
       "                                                   &#x27;logins_per_course&#x27;,\n",
       "                                                   &#x27;avg_time_per_login&#x27;,\n",
       "                                                   &#x27;avg_time_by_completed_content&#x27;,\n",
       "                                                   &#x27;quiz_attempts_per_quiz&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;term&#x27;, &#x27;pseudo_course&#x27;,\n",
       "                                                   &#x27;gender&#x27;, &#x27;imm_status&#x27;])])),\n",
       "                (&#x27;model&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;log_transform&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;,\n",
       "                                                                      inverse_func=&lt;ufunc &#x27;expm1&#x27;&gt;))]),\n",
       "                                 [&#x27;content_required&#x27;, &#x27;checklist_completed&#x27;,\n",
       "                                  &#x27;discussion_post_read&#x27;,\n",
       "                                  &#x27;number_of_assignment_submissions&#x27;,\n",
       "                                  &#x27;total_time_spent_in_content&#x27;, &#x27;age&#x27;,\n",
       "                                  &#x27;total_course_count&#x27;, &#x27;course_count_by_term&#x27;,\n",
       "                                  &#x27;completion_ratio&#x27;, &#x27;logins_per_course&#x27;,\n",
       "                                  &#x27;avg_time_per_login&#x27;,\n",
       "                                  &#x27;avg_time_by_completed_content&#x27;,\n",
       "                                  &#x27;quiz_attempts_per_quiz&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;term&#x27;, &#x27;pseudo_course&#x27;, &#x27;gender&#x27;,\n",
       "                                  &#x27;imm_status&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;content_required&#x27;, &#x27;checklist_completed&#x27;, &#x27;discussion_post_read&#x27;, &#x27;number_of_assignment_submissions&#x27;, &#x27;total_time_spent_in_content&#x27;, &#x27;age&#x27;, &#x27;total_course_count&#x27;, &#x27;course_count_by_term&#x27;, &#x27;completion_ratio&#x27;, &#x27;logins_per_course&#x27;, &#x27;avg_time_per_login&#x27;, &#x27;avg_time_by_completed_content&#x27;, &#x27;quiz_attempts_per_quiz&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=0, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;, inverse_func=&lt;ufunc &#x27;expm1&#x27;&gt;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;term&#x27;, &#x27;pseudo_course&#x27;, &#x27;gender&#x27;, &#x27;imm_status&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('log_transform',\n",
       "                                                                   FunctionTransformer(func=<ufunc 'log1p'>,\n",
       "                                                                                       inverse_func=<ufunc 'expm1'>))]),\n",
       "                                                  ['content_required',\n",
       "                                                   'checklist_completed',\n",
       "                                                   'discussion_post_read',\n",
       "                                                   'number_of_assignment_submissions',\n",
       "                                                   'total_time_sp...\n",
       "                                                   'age', 'total_course_count',\n",
       "                                                   'course_count_by_term',\n",
       "                                                   'completion_ratio',\n",
       "                                                   'logins_per_course',\n",
       "                                                   'avg_time_per_login',\n",
       "                                                   'avg_time_by_completed_content',\n",
       "                                                   'quiz_attempts_per_quiz']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  ['term', 'pseudo_course',\n",
       "                                                   'gender', 'imm_status'])])),\n",
       "                ('model', RandomForestClassifier())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline to your training data\n",
    "pipeline_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fc3ed12-62ce-433d-86fa-1a9936393a23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_rfc = pipeline_rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f9557-59ec-4fca-9a3b-5e6d364192a7",
   "metadata": {},
   "source": [
    "### Evaluate RandomForestClassifier\n",
    "\n",
    "#### Here we will check the accuracy, precision, recall, and f1-score, along with a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e65cd52a-6d87-4856-89a3-8c47a6731904",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9670958512160229\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1322\n",
      "           1       1.00      0.39      0.57        76\n",
      "\n",
      "    accuracy                           0.97      1398\n",
      "   macro avg       0.98      0.70      0.77      1398\n",
      "weighted avg       0.97      0.97      0.96      1398\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1322    0]\n",
      " [  46   30]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy_rfc = accuracy_score(y_test, y_pred_rfc)\n",
    "classification_rep_rfc = classification_report(y_test, y_pred_rfc)\n",
    "conf_matrix_rfc = confusion_matrix(y_test, y_pred_rfc)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_rfc}\")\n",
    "print(\"Classification Report:\\n\", classification_rep_rfc)\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed34b47-0d07-4389-bd8d-552937531feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b88ff9b-6e06-4f42-9ff7-8b20bd67f41d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 2: GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "424faca0-3999-4ce3-a2f2-787c549e956b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_gbc = GradientBoostingClassifier()\n",
    "pipeline_gbc = build_full_pipeline(preprocessor, model_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be3e88ff-7b96-40be-855c-58017b112eef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;log_transform&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;,\n",
       "                                                                                       inverse_func=&lt;ufunc &#x27;expm1&#x27;&gt;))]),\n",
       "                                                  [&#x27;content_required&#x27;,\n",
       "                                                   &#x27;checklist_completed&#x27;,\n",
       "                                                   &#x27;discussion_post_read&#x27;,\n",
       "                                                   &#x27;number_of_assignment_submissions&#x27;,\n",
       "                                                   &#x27;total_time_sp...\n",
       "                                                   &#x27;age&#x27;, &#x27;total_course_count&#x27;,\n",
       "                                                   &#x27;course_count_by_term&#x27;,\n",
       "                                                   &#x27;completion_ratio&#x27;,\n",
       "                                                   &#x27;logins_per_course&#x27;,\n",
       "                                                   &#x27;avg_time_per_login&#x27;,\n",
       "                                                   &#x27;avg_time_by_completed_content&#x27;,\n",
       "                                                   &#x27;quiz_attempts_per_quiz&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;term&#x27;, &#x27;pseudo_course&#x27;,\n",
       "                                                   &#x27;gender&#x27;, &#x27;imm_status&#x27;])])),\n",
       "                (&#x27;model&#x27;, GradientBoostingClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;log_transform&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;,\n",
       "                                                                                       inverse_func=&lt;ufunc &#x27;expm1&#x27;&gt;))]),\n",
       "                                                  [&#x27;content_required&#x27;,\n",
       "                                                   &#x27;checklist_completed&#x27;,\n",
       "                                                   &#x27;discussion_post_read&#x27;,\n",
       "                                                   &#x27;number_of_assignment_submissions&#x27;,\n",
       "                                                   &#x27;total_time_sp...\n",
       "                                                   &#x27;age&#x27;, &#x27;total_course_count&#x27;,\n",
       "                                                   &#x27;course_count_by_term&#x27;,\n",
       "                                                   &#x27;completion_ratio&#x27;,\n",
       "                                                   &#x27;logins_per_course&#x27;,\n",
       "                                                   &#x27;avg_time_per_login&#x27;,\n",
       "                                                   &#x27;avg_time_by_completed_content&#x27;,\n",
       "                                                   &#x27;quiz_attempts_per_quiz&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;term&#x27;, &#x27;pseudo_course&#x27;,\n",
       "                                                   &#x27;gender&#x27;, &#x27;imm_status&#x27;])])),\n",
       "                (&#x27;model&#x27;, GradientBoostingClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;log_transform&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;,\n",
       "                                                                      inverse_func=&lt;ufunc &#x27;expm1&#x27;&gt;))]),\n",
       "                                 [&#x27;content_required&#x27;, &#x27;checklist_completed&#x27;,\n",
       "                                  &#x27;discussion_post_read&#x27;,\n",
       "                                  &#x27;number_of_assignment_submissions&#x27;,\n",
       "                                  &#x27;total_time_spent_in_content&#x27;, &#x27;age&#x27;,\n",
       "                                  &#x27;total_course_count&#x27;, &#x27;course_count_by_term&#x27;,\n",
       "                                  &#x27;completion_ratio&#x27;, &#x27;logins_per_course&#x27;,\n",
       "                                  &#x27;avg_time_per_login&#x27;,\n",
       "                                  &#x27;avg_time_by_completed_content&#x27;,\n",
       "                                  &#x27;quiz_attempts_per_quiz&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;term&#x27;, &#x27;pseudo_course&#x27;, &#x27;gender&#x27;,\n",
       "                                  &#x27;imm_status&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;content_required&#x27;, &#x27;checklist_completed&#x27;, &#x27;discussion_post_read&#x27;, &#x27;number_of_assignment_submissions&#x27;, &#x27;total_time_spent_in_content&#x27;, &#x27;age&#x27;, &#x27;total_course_count&#x27;, &#x27;course_count_by_term&#x27;, &#x27;completion_ratio&#x27;, &#x27;logins_per_course&#x27;, &#x27;avg_time_per_login&#x27;, &#x27;avg_time_by_completed_content&#x27;, &#x27;quiz_attempts_per_quiz&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=0, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;ufunc &#x27;log1p&#x27;&gt;, inverse_func=&lt;ufunc &#x27;expm1&#x27;&gt;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;term&#x27;, &#x27;pseudo_course&#x27;, &#x27;gender&#x27;, &#x27;imm_status&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value=0,\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('log_transform',\n",
       "                                                                   FunctionTransformer(func=<ufunc 'log1p'>,\n",
       "                                                                                       inverse_func=<ufunc 'expm1'>))]),\n",
       "                                                  ['content_required',\n",
       "                                                   'checklist_completed',\n",
       "                                                   'discussion_post_read',\n",
       "                                                   'number_of_assignment_submissions',\n",
       "                                                   'total_time_sp...\n",
       "                                                   'age', 'total_course_count',\n",
       "                                                   'course_count_by_term',\n",
       "                                                   'completion_ratio',\n",
       "                                                   'logins_per_course',\n",
       "                                                   'avg_time_per_login',\n",
       "                                                   'avg_time_by_completed_content',\n",
       "                                                   'quiz_attempts_per_quiz']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  ['term', 'pseudo_course',\n",
       "                                                   'gender', 'imm_status'])])),\n",
       "                ('model', GradientBoostingClassifier())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline to your training data\n",
    "pipeline_gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20e9a4a6-570d-4c8e-9dcc-7adc058c692d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_gbc = pipeline_gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b24a4d-48e9-44ed-9fcc-aaf6558547a1",
   "metadata": {},
   "source": [
    "### Evaluate GradientBoostingClassifier\n",
    "\n",
    "#### Here we will check the accuracy, precision, recall, and f1-score, along with a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2746866-c636-45b0-8f58-bbfd9f1dbc4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9706723891273248\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1322\n",
      "           1       0.91      0.51      0.66        76\n",
      "\n",
      "    accuracy                           0.97      1398\n",
      "   macro avg       0.94      0.76      0.82      1398\n",
      "weighted avg       0.97      0.97      0.97      1398\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1318    4]\n",
      " [  37   39]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy_gbc = accuracy_score(y_test, y_pred_gbc)\n",
    "classification_rep_gbc = classification_report(y_test, y_pred_gbc)\n",
    "conf_matrix_gbc = confusion_matrix(y_test, y_pred_gbc)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_gbc}\")\n",
    "print(\"Classification Report:\\n\", classification_rep_gbc)\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix_gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e68d03-b845-4b7f-aced-9ea263bd33da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Observations\n",
    "\n",
    "- We can see that, while the accuracy is very high, we do not have the recall values we'd like to see for the under-represented group.\n",
    "- In this instance, since we aim to identify at-risk students, we would be willing to risk having more False Positives in order to minimize on the False Negatives.  In other words, it's far less problematic to have a student who is not at-risk be incorrectly identified as at risk than it is to have students who are actually at-risk not identified.\n",
    "- Let's check some other classification models to find out how they perform out of the box on this imbalanced dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd67366-6b8d-4cfb-8185-8a3111a5f172",
   "metadata": {},
   "source": [
    "# Testing Other Classifiers\n",
    "\n",
    "#### We've also included a dictionary that logs which entries(rows) are False Negatives for each of the classifiers.  Since this dataset is quite imbalanced, we will need to try various techniques in order to increase the recall rate.  By collecting the false negatives, we can hopefully get an idea of why these entries are difficult to classify correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2879f4bd-1c2e-4eb7-ba89-7a4c69b52f94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "\n",
      "Accuracy: 0.9649499284692418\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1322\n",
      "           1       0.97      0.37      0.53        76\n",
      "\n",
      "    accuracy                           0.96      1398\n",
      "   macro avg       0.97      0.68      0.76      1398\n",
      "weighted avg       0.96      0.96      0.96      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1321    1]\n",
      " [  48   28]]\n",
      "False Negatives Indices: [   3   20   40  138  151  178  201  233  307  325  392  409  412  457\n",
      "  481  527  539  542  578  668  696  698  716  734  778  792  794  848\n",
      "  891  902  906  962  979 1038 1059 1061 1105 1108 1241 1245 1250 1272\n",
      " 1283 1318 1327 1341 1378 1396]\n",
      "------------------------------------------------------------------\n",
      "\n",
      "GradientBoosting\n",
      "\n",
      "Accuracy: 0.969241773962804\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1322\n",
      "           1       0.87      0.51      0.64        76\n",
      "\n",
      "    accuracy                           0.97      1398\n",
      "   macro avg       0.92      0.75      0.81      1398\n",
      "weighted avg       0.97      0.97      0.97      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1316    6]\n",
      " [  37   39]]\n",
      "False Negatives Indices: [   3   40  138  151  178  201  307  325  392  412  457  539  542  583\n",
      "  668  696  698  716  734  778  794  891  962  979 1038 1059 1061 1103\n",
      " 1108 1245 1250 1272 1283 1318 1327 1341 1378]\n",
      "------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jlo/anaconda3/envs/newenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jlo/anaconda3/envs/newenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jlo/anaconda3/envs/newenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "\n",
      "Accuracy: 0.9456366237482118\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1322\n",
      "           1       0.00      0.00      0.00        76\n",
      "\n",
      "    accuracy                           0.95      1398\n",
      "   macro avg       0.47      0.50      0.49      1398\n",
      "weighted avg       0.89      0.95      0.92      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1322    0]\n",
      " [  76    0]]\n",
      "False Negatives Indices: [   3   13   20   30   40   41   72  132  138  151  178  201  233  279\n",
      "  307  309  325  353  389  392  402  409  412  417  440  457  481  527\n",
      "  539  542  558  578  583  668  673  678  696  698  716  734  778  792\n",
      "  794  848  891  894  902  906  916  962  979 1019 1038 1059 1061 1069\n",
      " 1096 1103 1105 1108 1117 1139 1179 1241 1245 1249 1250 1272 1275 1283\n",
      " 1318 1327 1341 1346 1378 1396]\n",
      "------------------------------------------------------------------\n",
      "\n",
      "KNN\n",
      "\n",
      "Accuracy: 0.957796852646638\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1322\n",
      "           1       0.76      0.33      0.46        76\n",
      "\n",
      "    accuracy                           0.96      1398\n",
      "   macro avg       0.86      0.66      0.72      1398\n",
      "weighted avg       0.95      0.96      0.95      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1314    8]\n",
      " [  51   25]]\n",
      "False Negatives Indices: [   3   13   20   30   40  132  138  151  178  201  233  307  325  392\n",
      "  409  412  457  481  527  539  542  583  668  696  698  716  734  778\n",
      "  792  794  848  891  902  962  979 1038 1059 1061 1103 1105 1108 1241\n",
      " 1245 1250 1272 1283 1318 1327 1341 1378 1396]\n",
      "------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jlo/anaconda3/envs/newenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "\n",
      "Accuracy: 0.9549356223175965\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1322\n",
      "           1       0.71      0.29      0.41        76\n",
      "\n",
      "    accuracy                           0.95      1398\n",
      "   macro avg       0.84      0.64      0.69      1398\n",
      "weighted avg       0.95      0.95      0.95      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1313    9]\n",
      " [  54   22]]\n",
      "False Negatives Indices: [   3   20   30   40  132  138  151  178  201  233  307  325  389  392\n",
      "  409  412  457  481  527  539  542  578  583  696  698  716  734  778\n",
      "  792  794  848  891  902  906  962  979 1038 1059 1061 1103 1108 1117\n",
      " 1241 1245 1249 1250 1272 1283 1318 1327 1341 1346 1378 1396]\n",
      "------------------------------------------------------------------\n",
      "\n",
      "RidgeRegression\n",
      "\n",
      "Accuracy: 0.9556509298998569\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1322\n",
      "           1       0.72      0.30      0.43        76\n",
      "\n",
      "    accuracy                           0.96      1398\n",
      "   macro avg       0.84      0.65      0.70      1398\n",
      "weighted avg       0.95      0.96      0.95      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1313    9]\n",
      " [  53   23]]\n",
      "False Negatives Indices: [   3   20   40  132  138  151  178  201  233  307  309  325  392  409\n",
      "  412  457  481  527  539  542  578  583  668  696  698  716  734  778\n",
      "  792  794  848  891  902  962  979 1038 1059 1061 1103 1105 1108 1179\n",
      " 1241 1245 1249 1250 1272 1283 1318 1327 1341 1378 1396]\n",
      "------------------------------------------------------------------\n",
      "\n",
      "NaiveBayes\n",
      "\n",
      "Accuracy: 0.5565092989985694\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.54      0.70      1322\n",
      "           1       0.10      0.86      0.17        76\n",
      "\n",
      "    accuracy                           0.56      1398\n",
      "   macro avg       0.54      0.70      0.44      1398\n",
      "weighted avg       0.94      0.56      0.67      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[713 609]\n",
      " [ 11  65]]\n",
      "False Negatives Indices: [ 392  440  583  673 1059 1061 1241 1245 1249 1250 1318]\n",
      "------------------------------------------------------------------\n",
      "\n",
      "NeuralNetwork\n",
      "\n",
      "Accuracy: 0.9678111587982833\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1322\n",
      "           1       0.79      0.55      0.65        76\n",
      "\n",
      "    accuracy                           0.97      1398\n",
      "   macro avg       0.88      0.77      0.82      1398\n",
      "weighted avg       0.96      0.97      0.97      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1311   11]\n",
      " [  34   42]]\n",
      "False Negatives Indices: [   3  132  138  178  201  325  392  409  457  527  539  583  668  673\n",
      "  698  716  734  778  792  794  979 1059 1061 1108 1241 1245 1249 1250\n",
      " 1272 1283 1318 1327 1341 1378]\n",
      "------------------------------------------------------------------\n",
      "\n",
      "XGBoost\n",
      "\n",
      "Accuracy: 0.969241773962804\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1322\n",
      "           1       0.85      0.53      0.65        76\n",
      "\n",
      "    accuracy                           0.97      1398\n",
      "   macro avg       0.91      0.76      0.82      1398\n",
      "weighted avg       0.97      0.97      0.97      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1315    7]\n",
      " [  36   40]]\n",
      "False Negatives Indices: [   3   20   40  151  178  201  233  325  412  457  481  542  696  698\n",
      "  716  734  778  794  848  891  906  962  979 1038 1059 1061 1105 1108\n",
      " 1241 1245 1250 1272 1318 1327 1341 1396]\n",
      "------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'GradientBoosting': GradientBoostingClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=400),\n",
    "    'RidgeRegression': RidgeClassifier(),\n",
    "    'NaiveBayes': GaussianNB(),\n",
    "    'NeuralNetwork': MLPClassifier(max_iter=400),\n",
    "    'XGBoost': xgb.XGBClassifier()\n",
    "    \n",
    "}\n",
    "\n",
    "# Create an empty dictionary to store False Negatives for each classifier\n",
    "false_negatives_dict = {}\n",
    "\n",
    "# Create an empty list to store DataFrames for each classifier\n",
    "false_negatives_dfs = []\n",
    "\n",
    "# Iterate through classifiers\n",
    "for clf_name, clf in classifiers.items():\n",
    "    pipeline = build_full_pipeline(preprocessor, clf)\n",
    "    grid_search = GridSearchCV(pipeline, {}, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # Identify False Negatives\n",
    "    false_negatives = (y_test == 1) & (y_pred == 0)\n",
    "\n",
    "    # Extract indices of False Negatives\n",
    "    fn_indices = np.where(false_negatives)[0]\n",
    "    \n",
    "    # Extract False Negatives entries from the DataFrame\n",
    "    fn_entries = X_test[false_negatives]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Append False Negatives entries to the list\n",
    "    fn_entries_copy = fn_entries.copy()\n",
    "    fn_entries_copy['Classifier'] = clf_name\n",
    "    false_negatives_dfs.append(fn_entries_copy)\n",
    "    \n",
    "    # Store False Negatives indices in the dictionary\n",
    "    false_negatives_dict[clf_name] = fn_indices\n",
    "\n",
    "    print(f\"{clf_name}\\n\")\n",
    "    print(f\"Accuracy: {accuracy}\\n\")\n",
    "    print(\"Classification Report:\\n\", classification_rep)\n",
    "    print('Confusion Matrix:\\n', conf_matrix)\n",
    "    print(f'False Negatives Indices: {fn_indices}')\n",
    "    print(\"------------------------------------------------------------------\\n\")\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "false_negatives_df = pd.concat(false_negatives_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781963aa-9d8f-400b-a7ca-420ec01cec61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "479aadf1-8842-45ec-8e4d-71288101d1f3",
   "metadata": {},
   "source": [
    "## Observations\n",
    "- Again, we see that most models have a very high accuracy, but many have a recall rate of less than 50% for the under-represented class.\n",
    "- Naive Bayes has the best Recall, but this comes at the cost of having a significant decrease to accuracy and recall for the over-represented class.  While it is unfeasible to misclassify half of the student population as at-risk, maybe we can leverage this model's predictions in an ensemble model.\n",
    "- The Nueral Network, GradientBoost, and XGBoost models are showing some signs of hope as well, all with recall values of > 50%.\n",
    "\n",
    "### Moving Forward\n",
    "- We will have to try tuning some of these models, combined with other methods that can deal with imbalanced datasets in our hyperparameter_tuning notebook.\n",
    "- Before the hyperparameter tuning, we will take a closer look at the dictionary of false negatives we created to determine if we can find out more about the entries that are not being classified properly.  This investigation can be found in the EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81b0631f-b9fa-44a3-9604-73fdafe90a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save false_negatives_dict and df to a file in order to use in the EDA notebook\n",
    "with open('data/processed_data/false_negatives_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(false_negatives_dict, file)\n",
    "    \n",
    "false_negatives_df.to_csv('data/processed_data/false_negatives_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb19c4-5c77-4ee4-a970-90f99a8b8565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2400d487-41c9-412c-8bdd-c01d6950fe03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2928d498-a1c9-4d8b-8902-8866e7e5e9a2",
   "metadata": {},
   "source": [
    "# Creating A Stack Model\n",
    "\n",
    "#### This model combines the top 3 performing models from aboveL XGBoost, Naive Bayes, and Neural Net.  From above, we can see that both the Neural Net and XGBoost had a couple of the better recall scores for the under-represented class, except for the Naive Bayes, which had the best recall score overall (at the cost of many False Positives).\n",
    "\n",
    "#### We've included class_weights to combat the imbalance in the dataset\n",
    "\n",
    "#### This first pass will not include any hyperparameter tuning to get a baseline of what we can achieve with this stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac83af3e-795c-42c2-8586-94290e9452c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9649499284692418\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1322\n",
      "           1       0.75      0.53      0.62        76\n",
      "\n",
      "    accuracy                           0.96      1398\n",
      "   macro avg       0.86      0.76      0.80      1398\n",
      "weighted avg       0.96      0.96      0.96      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1309   13]\n",
      " [  36   40]]\n"
     ]
    }
   ],
   "source": [
    "# Define class weights\n",
    "class_weights = {\n",
    "    0: 0.05,\n",
    "    1: 0.95,\n",
    "}\n",
    "\n",
    "# Update base classifiers with class weights\n",
    "xgb_model = build_full_pipeline(preprocessor, xgb.XGBClassifier())\n",
    "nb_model = build_full_pipeline(preprocessor, GaussianNB()) \n",
    "nn_model = build_full_pipeline(preprocessor, MLPClassifier(max_iter=400))\n",
    "\n",
    "# Update meta-classifier with class weights\n",
    "meta_classifier = RandomForestClassifier(class_weight=class_weights)\n",
    "\n",
    "# Create the stacking classifier with class weights\n",
    "stacking_classifier = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_model),\n",
    "        ('nn', nn_model),\n",
    "        ('nb', nb_model)\n",
    "    ],\n",
    "    final_estimator=meta_classifier,\n",
    "    cv=5  # Number of cross-validation folds\n",
    ")\n",
    "\n",
    "# Train the stacking classifier\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "stack_pred = stacking_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, stack_pred)\n",
    "classification_rep = classification_report(y_test, stack_pred)\n",
    "conf_matrix = confusion_matrix(y_test, stack_pred)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print('Confusion Matrix:\\n', conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ebb3af-8d0c-4e5a-a9b5-3952868d40f5",
   "metadata": {},
   "source": [
    "### Results:\n",
    "- This is performing about the same as XGBoost and Neural Net did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d1c585-19f1-42a6-8a71-19c89b59532c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c1c2f03-127b-45b1-8842-9d94fde89a37",
   "metadata": {},
   "source": [
    "## Retraining the Stacked Model (with hypertuned XGBoost and Neural Net)\n",
    "- The models loaded in are the tuned models from the \"hyperparameter_tuning\" notebook\n",
    "- We will see if we can improve on the prior baseline stacked model with these tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8af7a68-edea-47ee-acb5-36657d6cfaeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load saved models and best parameters\n",
    "best_model_xgb_model = joblib.load('models/best_model_xgb_roc.pkl')\n",
    "best_xgb_params = joblib.load('models/best_xgb_params.pkl')\n",
    "\n",
    "# Load saved models and best parameters\n",
    "tuned_nn_model = joblib.load('models/tuned_nn_model.pkl')\n",
    "best_nn_params = joblib.load('models/best_nn_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797bfaf7-4cfe-477f-b0f7-e2094ccaf5b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab8614eb-040c-4403-b019-185102b3a423",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9628040057224606\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1322\n",
      "           1       0.69      0.58      0.63        76\n",
      "\n",
      "    accuracy                           0.96      1398\n",
      "   macro avg       0.83      0.78      0.80      1398\n",
      "weighted avg       0.96      0.96      0.96      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1302   20]\n",
      " [  32   44]]\n"
     ]
    }
   ],
   "source": [
    "# Define class weights\n",
    "class_weights = {\n",
    "    0: 0.05,\n",
    "    1: 0.95,\n",
    "    # Add weights for other classes if applicable\n",
    "}\n",
    "\n",
    "# Base Classifiers\n",
    "xgb_model = best_model_xgb_model\n",
    "nb_model_mod = build_full_pipeline(preprocessor, GaussianNB())\n",
    "nn_model_mod = build_full_pipeline(preprocessor, MLPClassifier(alpha=0.01, \n",
    "                                                               hidden_layer_sizes=(50,), \n",
    "                                                               learning_rate='adaptive', \n",
    "                                                               max_iter=500, \n",
    "                                                               solver='adam'))\n",
    "\n",
    "# Update meta-classifier with class weights\n",
    "meta_classifier = RandomForestClassifier(class_weight=class_weights)\n",
    "\n",
    "# Create the stacking classifier with class weights\n",
    "stacking_classifier = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_model),\n",
    "        ('nn', nn_model),\n",
    "        ('nb', nb_model)\n",
    "    ],\n",
    "    final_estimator=meta_classifier,\n",
    "    cv=5  # Number of cross-validation folds\n",
    ")\n",
    "\n",
    "# Train the stacking classifier\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "stack_pred = stacking_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, stack_pred)\n",
    "classification_rep = classification_report(y_test, stack_pred)\n",
    "conf_matrix = confusion_matrix(y_test, stack_pred)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print('Confusion Matrix:\\n', conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98614d59-1ee4-4fad-a12c-15af788232cf",
   "metadata": {},
   "source": [
    "### Results:\n",
    "- We can see only a slight improvement for recall.  Not enough to definitively say this model is better than previous, especially considering the tuned xgboost model had a recall of 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45548cce-fab1-4f2f-b0dd-8cb324c2181a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b724c49-9855-4764-aef9-2a9397800ce3",
   "metadata": {},
   "source": [
    "# Creating a Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd7130-c0b9-41eb-86b7-1147932edaa0",
   "metadata": {},
   "source": [
    "#### Let's try another ensemble model, this time a voting classifier.  In this case, we hope to draw on the strengths (and weaknesses) of the various classifiers to create a more well-rounded model.\n",
    "\n",
    "#### For the first pass, we'll try a combination of 4 classifiers - XGBoost, Naive Bayes, Neural Net, and Gradient Boost.  We will use the un-tuned models first\n",
    "#### Since the Naive Bayes has the highest recall on the under-represented class, we'll give it a voting weight of 2, with all the others a weight of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eeef484-bf76-401d-9900-5576497f21f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create individual models\n",
    "xgb_model = build_full_pipeline(preprocessor, XGBClassifier())\n",
    "nb_model = build_full_pipeline(preprocessor, GaussianNB())\n",
    "nn_model = build_full_pipeline(preprocessor, MLPClassifier())\n",
    "gb_model = build_full_pipeline(preprocessor, GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9589f8f-c508-4a00-8672-8f6cb2fb262c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jlo/anaconda3/envs/newenv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Build a VotingClassifier with custom weights\n",
    "custom_weights = [2, 1, 1, 1]  #classifier_weights\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('nb', nb_model), ('nn', nn_model), ('xgb', xgb_model), ('gb', gb_model)],\n",
    "    voting='soft',  \n",
    "    weights=custom_weights\n",
    ")\n",
    "\n",
    "# Fit the ensemble model on the training data\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "ensemble_predictions = ensemble_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e994fdf-e7ef-4779-ac73-dddde41416a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9620886981402003\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1322\n",
      "           1       0.62      0.78      0.69        76\n",
      "\n",
      "    accuracy                           0.96      1398\n",
      "   macro avg       0.80      0.87      0.83      1398\n",
      "weighted avg       0.97      0.96      0.96      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1286   36]\n",
      " [  17   59]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "classification_rep = classification_report(y_test, ensemble_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, ensemble_predictions)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print('Confusion Matrix:\\n', conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc668d60-b531-4f4d-9f94-4994f837d5c3",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "- This is a pretty good recall value for the under-represented class, the best we've seen yet at 78%.\n",
    "\n",
    "# Trying Multiple Classifiers and Weights\n",
    "\n",
    "#### Let's loop through multiple classifier and weight combinations to see if we can find the \"best\" combination for the voting classifier.\n",
    "\n",
    "#### **NOTE**: This chunk of code takes quite a while to run, so I've included the output afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "62d19477-30f0-4acd-b2aa-762985162c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create individual models\n",
    "xgb_model = build_full_pipeline(preprocessor, XGBClassifier())\n",
    "nb_model = build_full_pipeline(preprocessor, GaussianNB())\n",
    "nn_model = build_full_pipeline(preprocessor, MLPClassifier(max_iter=400))\n",
    "gb_model = build_full_pipeline(preprocessor, GradientBoostingClassifier())\n",
    "rf_model = build_full_pipeline(preprocessor, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7b5d3227-8167-4c6c-ab2f-9046ddb87fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Combination: (1, 0, 2, 0, 1), ROC_AUC: 0.8422545584839556\n",
      "Weight Combination: (1, 0, 1, 0, 1), ROC_AUC: 0.8422545584839556\n",
      "Weight Combination: (2, 1, 1, 1, 0), ROC_AUC: 0.8422545584839556\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from sklearn.metrics import roc_auc_score, recall_score\n",
    "\n",
    "# List of classifiers and their names\n",
    "classifiers = [nb_model, nn_model, xgb_model, gb_model, rf_model]\n",
    "classifier_names = ['nb', 'nn', 'xgb', 'gb', 'rf']\n",
    "\n",
    "# Range of weights (0 to 3, inclusive)\n",
    "weight_values = [0, 1, 2]\n",
    "\n",
    "# Store the top three weight combinations along with their recall scores\n",
    "top_three_combinations = []\n",
    "\n",
    "# Iterate over all possible weight combinations\n",
    "for weight_combination in product(weight_values, repeat=len(classifiers)):\n",
    "    # Ensure at least one weight for nb_model and not all weights are zero\n",
    "    if weight_combination[classifier_names.index('nb')] > 0 and any(weight_combination):\n",
    "        # Build the ensemble model with custom weights\n",
    "        ensemble_model = VotingClassifier(\n",
    "            estimators=list(zip(classifier_names, classifiers)),\n",
    "            voting='soft',\n",
    "            weights=weight_combination\n",
    "        )\n",
    "\n",
    "        # Fit the ensemble model on the training data\n",
    "        ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        ensemble_predictions = ensemble_model.predict(X_test)\n",
    "\n",
    "        # Evaluate Performance (use recall instead of accuracy)\n",
    "        roc_auc = roc_auc_score(y_test, ensemble_predictions)\n",
    "        \n",
    "        # Store the weight combination and recall score\n",
    "        top_three_combinations.append((weight_combination, roc_auc))\n",
    "\n",
    "# Sort and retrieve the top three combinations based on recall\n",
    "top_three_combinations.sort(key=lambda x: x[1], reverse=True)\n",
    "top_three_combinations = top_three_combinations[:3]\n",
    "\n",
    "# Print the top three weight combinations and their recall scores\n",
    "for combination, roc_auc in top_three_combinations:\n",
    "    print(f\"Weight Combination: {combination}, ROC_AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70081cb-4e45-4b91-9b3c-71a52a7ec88b",
   "metadata": {},
   "source": [
    "### Results:\n",
    "For models (NB, NN, XGB, GB, RF), the weights for the top 3 ROC_AUC combination scores:\n",
    "- Weight Combination: (1, 0, 2, 0, 1), ROC_AUC: 0.8422545584839556\n",
    "- Weight Combination: (1, 0, 1, 0, 1), ROC_AUC: 0.8422545584839556\n",
    "- Weight Combination: (2, 1, 1, 1, 0), ROC_AUC: 0.8422545584839556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac3ecc7-f793-42c7-a871-a2867ecab35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66f9d8cf-769d-45b0-bef2-dc0e617d36cf",
   "metadata": {},
   "source": [
    "## Trying the top combinations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62497d43-7a3b-46af-9804-c878e27318ec",
   "metadata": {},
   "source": [
    "#### 1. Weight Combination: (NB=1, NN=0, XGB=2, GB=0, RF=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "35f0c26a-795d-4525-bb9e-46f45854a340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build a VotingClassifier with custom weights\n",
    "custom_weights = [1, 2, 1]  #classifier_weights\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('nb', nb_model), \n",
    "                ('xgb', xgb_model), \n",
    "                ('rf', rf_model)],\n",
    "    voting='soft',  \n",
    "    weights=custom_weights\n",
    ")\n",
    "\n",
    "# Fit the ensemble model on the training data\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "ensemble_predictions = ensemble_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b3c88586-a9fb-4650-a38d-b14165398763",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9549356223175965\n",
      "\n",
      "ROC_AUC: 0.8831614778246676\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      1322\n",
      "           1       0.56      0.80      0.66        76\n",
      "\n",
      "    accuracy                           0.95      1398\n",
      "   macro avg       0.77      0.88      0.82      1398\n",
      "weighted avg       0.97      0.95      0.96      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1274   48]\n",
      " [  15   61]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "classification_rep = classification_report(y_test, ensemble_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, ensemble_predictions)\n",
    "roc_auc = roc_auc_score(y_test, ensemble_predictions)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(f\"ROC_AUC: {roc_auc}\\n\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print('Confusion Matrix:\\n', conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69874ef8-eea1-46fe-9ff3-3b5296ca24a6",
   "metadata": {},
   "source": [
    "#### 2. Weight Combination: (NB=1, NN=0, XGB=1, GB=0, RF=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "65af37dc-ff97-4cc8-ac48-a8a3361395f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build a VotingClassifier with custom weights\n",
    "custom_weights = [1, 1, 1]  #classifier_weights\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('nb', nb_model), \n",
    "                ('xgb', xgb_model), \n",
    "                ('rf', rf_model)],\n",
    "    voting='soft',  \n",
    "    weights=custom_weights\n",
    ")\n",
    "\n",
    "# Fit the ensemble model on the training data\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "ensemble_predictions = ensemble_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0ac0844c-c6fe-40d1-93d3-0466e4e6b009",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9470672389127325\n",
      "\n",
      "ROC_AUC: 0.8728003821960347\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      1322\n",
      "           1       0.51      0.79      0.62        76\n",
      "\n",
      "    accuracy                           0.95      1398\n",
      "   macro avg       0.75      0.87      0.80      1398\n",
      "weighted avg       0.96      0.95      0.95      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1264   58]\n",
      " [  16   60]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "classification_rep = classification_report(y_test, ensemble_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, ensemble_predictions)\n",
    "roc_auc = roc_auc_score(y_test, ensemble_predictions)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(f\"ROC_AUC: {roc_auc}\\n\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print('Confusion Matrix:\\n', conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ee5850-5331-4a06-baa3-e81cd19c81b1",
   "metadata": {},
   "source": [
    "#### 3. Weight Combination: (NB=2, NN=1, XGB=1, GB=1, RF=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "58e67187-db55-47d8-a860-24eb66879f94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build a VotingClassifier with custom weights\n",
    "custom_weights = [2, 1, 1, 1]  #classifier_weights\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('nb', nb_model), \n",
    "                ('nn', nn_model), \n",
    "                ('xgb', xgb_model),\n",
    "                ('gb', gb_model)],\n",
    "    voting='soft',  \n",
    "    weights=custom_weights\n",
    ")\n",
    "\n",
    "# Fit the ensemble model on the training data\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "ensemble_predictions = ensemble_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8075ae9b-ff2f-49a5-ab9b-0c327b1f200c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9449213161659513\n",
      "\n",
      "ROC_AUC: 0.8716657377179712\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1322\n",
      "           1       0.50      0.79      0.61        76\n",
      "\n",
      "    accuracy                           0.94      1398\n",
      "   macro avg       0.74      0.87      0.79      1398\n",
      "weighted avg       0.96      0.94      0.95      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1261   61]\n",
      " [  16   60]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "classification_rep = classification_report(y_test, ensemble_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, ensemble_predictions)\n",
    "roc_auc = roc_auc_score(y_test, ensemble_predictions)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(f\"ROC_AUC: {roc_auc}\\n\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print('Confusion Matrix:\\n', conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f85e457-0730-44ec-a715-9f00726f87b2",
   "metadata": {},
   "source": [
    "### Results:\n",
    "- All three models are performing quite similarly, with a recall of the under-represented class of ~80%.\n",
    "- The first model with model and weight combination: (NB=1, XGB=2, RF=1) has a better recall on the majority class (less False Positives)\n",
    "- Let's retry these models with the results of the hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293bbe4b-e29f-4c11-a347-885eb301f054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a31e1c72-6e34-49b5-a3aa-a8335ee46a09",
   "metadata": {},
   "source": [
    "# Voting Classifiers with Tuned Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb5d31d-16e9-4390-9ee1-0e101047b86a",
   "metadata": {},
   "source": [
    "Let's try to find the \"best\" weight combination again, but this time with the tuned models from the results of the hyperparameter_tuning notebook, with roc_auc as our scoring metric:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb59f5e-aac9-4394-a499-a68ba100fcc2",
   "metadata": {},
   "source": [
    "### a) df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "a2d05987-1e96-41a6-b872-37566ef47350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create individual models\n",
    "xgb_model = build_full_pipeline(preprocessor, XGBClassifier(learning_rate=0.2, \n",
    "                                                            max_depth=3, \n",
    "                                                            n_estimators=100, \n",
    "                                                            scale_pos_weight=5))\n",
    "nb_model = build_full_pipeline(preprocessor, GaussianNB())\n",
    "nn_model = build_full_pipeline(preprocessor, MLPClassifier(alpha=0.01, \n",
    "                                                           hidden_layer_sizes=(100,),\n",
    "                                                           learning_rate='adaptive', \n",
    "                                                           max_iter=400,\n",
    "                                                           solver='adam'))\n",
    "gb_model = build_full_pipeline(preprocessor, GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                                                        max_depth=3,\n",
    "                                                                        n_estimators=300))\n",
    "rf_model = build_full_pipeline(preprocessor, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ff102893-6f22-4aca-9264-36c04971ba28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Combination: (1, 0, 3, 0, 0), ROC_AUC: 0.8891332908671071\n",
      "Weight Combination: (3, 3, 3, 0, 0), ROC_AUC: 0.8887550760410861\n",
      "Weight Combination: (3, 1, 0, 1, 2), ROC_AUC: 0.8864857870849591\n",
      "Weight Combination: (3, 1, 0, 3, 0), ROC_AUC: 0.884594712954853\n",
      "Weight Combination: (3, 2, 1, 0, 3), ROC_AUC: 0.8842961223027312\n"
     ]
    }
   ],
   "source": [
    "# List of classifiers and their names\n",
    "classifiers = [nb_model, nn_model, xgb_model, gb_model, rf_model]\n",
    "classifier_names = ['nb', 'nn', 'xgb', 'gb', 'rf']\n",
    "\n",
    "# Range of weights (0 to 3, inclusive)\n",
    "weight_values = [0, 1, 2, 3]\n",
    "\n",
    "# Store the top five weight combinations along with their roc_auc scores\n",
    "combinations = []\n",
    "\n",
    "# Iterate over all possible weight combinations\n",
    "for weight_combination in product(weight_values, repeat=len(classifiers)):\n",
    "    # Ensure at least one weight for nb_model and not all weights are zero\n",
    "    if weight_combination[classifier_names.index('nb')] > 0 and any(weight_combination):\n",
    "        # Build the ensemble model with custom weights\n",
    "        ensemble_model = VotingClassifier(\n",
    "            estimators=list(zip(classifier_names, classifiers)),\n",
    "            voting='soft',\n",
    "            weights=weight_combination\n",
    "        )\n",
    "\n",
    "        # Fit the ensemble model on the training data\n",
    "        ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        ensemble_predictions = ensemble_model.predict(X_test)\n",
    "\n",
    "        # Evaluate Performance on roc_auc score\n",
    "        roc_auc = roc_auc_score(y_test, ensemble_predictions)\n",
    "        \n",
    "        # Store the weight combination and roc_auc score\n",
    "        combinations.append((weight_combination, roc_auc))\n",
    "\n",
    "# Sort and retrieve the top five combinations based on roc_auc score\n",
    "combinations.sort(key=lambda x: x[1], reverse=True)\n",
    "top_five_combinations = combinations[:5]\n",
    "\n",
    "# Print the top five weight combinations and their roc_auc scores\n",
    "for combination, roc_auc in top_five_combinations:\n",
    "    print(f\"Weight Combination: {combination}, ROC_AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11d33ea-63af-404d-8ba8-31baf7d88776",
   "metadata": {},
   "source": [
    "### Results:\n",
    "For models (NB, NN, XGB, GB, RF), the weights for the top 5 ROC_AUC combination scores:\n",
    "- Weight Combination: (1, 0, 3, 0, 0), ROC_AUC: 0.8891332908671071\n",
    "- Weight Combination: (3, 3, 3, 0, 0), ROC_AUC: 0.8887550760410861\n",
    "- Weight Combination: (3, 1, 0, 1, 2), ROC_AUC: 0.8864857870849591\n",
    "- Weight Combination: (3, 1, 0, 3, 0), ROC_AUC: 0.884594712954853\n",
    "- Weight Combination: (3, 2, 1, 0, 3), ROC_AUC: 0.8842961223027312\n",
    "\n",
    "After testing all of these results, it appears that the first weight combination produces the best recall for the under-represented class, while also minimizing the False Positives to a reasonable level.  Below is our model build with these weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "a356c020-8657-4c0d-9e13-7c21317eb5de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build a VotingClassifier with custom weights\n",
    "custom_weights = [1, 0, 3, 0, 0]  #classifier_weights\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('nb', nb_model), \n",
    "                ('nn', nn_model), \n",
    "                ('xgb', xgb_model), \n",
    "                ('gb', gb_model),\n",
    "                ('rf', rf_model)],\n",
    "    voting='soft',  \n",
    "    weights=custom_weights\n",
    ")\n",
    "\n",
    "# Fit the ensemble model on the training data\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "ensemble_predictions = ensemble_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8debb98f-da10-40a4-95d6-88e90df3f2e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9427753934191703\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1322\n",
      "           1       0.48      0.83      0.61        76\n",
      "\n",
      "    accuracy                           0.94      1398\n",
      "   macro avg       0.74      0.89      0.79      1398\n",
      "weighted avg       0.96      0.94      0.95      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1255   67]\n",
      " [  13   63]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "classification_rep = classification_report(y_test, ensemble_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, ensemble_predictions)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print('Confusion Matrix:\\n', conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0128035-ecfc-4751-8316-c602ffb6419e",
   "metadata": {},
   "source": [
    "### Results:\n",
    "- 83% recall is our best result yet.  While Naive Bayes had an out-of-box recall of 86%, it came at the cost of far too many false postives.  By combining Naive Bayes with XGBoost, we are able to bring the number of false positives to a reasonable amount, while also being within 3% of Naive Bayes' recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84397e3-6f7a-4c12-a7b8-ea5aee8e85e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5247f2d3-5207-4df5-a24d-b9897f287a99",
   "metadata": {},
   "source": [
    "### b) df_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "029b1bf0-e191-43ef-acaa-0bd0ee9bb434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create individual models\n",
    "xgb_model_mod = build_full_pipeline(preprocessor, xgb.XGBClassifier(learning_rate=0.4,\n",
    "                                                            max_depth=3, \n",
    "                                                            n_estimators=300, \n",
    "                                                            scale_pos_weight=9))\n",
    "nb_model_mod = build_full_pipeline(preprocessor, GaussianNB())\n",
    "nn_model_mod = build_full_pipeline(preprocessor, MLPClassifier(alpha=0.01, \n",
    "                                                               hidden_layer_sizes=(50,), \n",
    "                                                               learning_rate='adaptive', \n",
    "                                                               max_iter=500, \n",
    "                                                               solver='adam'))\n",
    "gb_model_mod = build_full_pipeline(preprocessor, GradientBoostingClassifier(learning_rate=0.1,\n",
    "                                                                            max_depth=3,\n",
    "                                                                            n_estimators=400))\n",
    "rf_model_mod = build_full_pipeline(preprocessor, RandomForestClassifier(max_features='sqrt', \n",
    "                                                                        min_samples_leaf=1, \n",
    "                                                                        min_samples_split=3, \n",
    "                                                                        n_estimators=400))\n",
    "                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "361af385-9c93-4029-b6d3-065bfe9a72be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Combination: (1, 0, 3, 0, 0), ROC_AUC: 0.8870132972370411\n",
      "Weight Combination: (2, 0, 3, 0, 1), ROC_AUC: 0.8839875786288717\n",
      "Weight Combination: (3, 1, 2, 1, 1), ROC_AUC: 0.8815689943466838\n",
      "Weight Combination: (3, 0, 2, 3, 0), ROC_AUC: 0.8802850545425591\n",
      "Weight Combination: (3, 0, 3, 1, 2), ROC_AUC: 0.8795286248905169\n"
     ]
    }
   ],
   "source": [
    "# List of classifiers and their names\n",
    "classifiers = [nb_model_mod, nn_model_mod, xgb_model_mod, gb_model_mod, rf_model_mod]\n",
    "classifier_names = ['nb', 'nn', 'xgb', 'gb', 'rf']\n",
    "\n",
    "# Range of weights (0 to 3, inclusive)\n",
    "weight_values = [0, 1, 2, 3]\n",
    "\n",
    "# Store the top five weight combinations along with their roc_auc scores\n",
    "combinations = []\n",
    "\n",
    "# Iterate over all possible weight combinations\n",
    "for weight_combination in product(weight_values, repeat=len(classifiers)):\n",
    "    # Ensure at least one weight for nb_model and not all weights are zero\n",
    "    if weight_combination[classifier_names.index('nb')] > 0 and any(weight_combination):\n",
    "        # Build the ensemble model with custom weights\n",
    "        ensemble_model = VotingClassifier(\n",
    "            estimators=list(zip(classifier_names, classifiers)),\n",
    "            voting='soft',\n",
    "            weights=weight_combination\n",
    "        )\n",
    "\n",
    "        # Fit the ensemble model on the training data\n",
    "        ensemble_model.fit(X_train2, y_train2)\n",
    "\n",
    "        # Make predictions\n",
    "        ensemble_predictions = ensemble_model.predict(X_test2)\n",
    "\n",
    "        # Evaluate Performance on roc_auc score\n",
    "        roc_auc = roc_auc_score(y_test2, ensemble_predictions)\n",
    "        \n",
    "        # Store the weight combination and roc_auc score\n",
    "        combinations.append((weight_combination, roc_auc))\n",
    "\n",
    "# Sort and retrieve the top five combinations based on roc_auc score\n",
    "combinations.sort(key=lambda x: x[1], reverse=True)\n",
    "top_five_combinations = combinations[:5]\n",
    "\n",
    "# Print the top five weight combinations and their roc_auc scores\n",
    "for combination, roc_auc in top_five_combinations:\n",
    "    print(f\"Weight Combination: {combination}, ROC_AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec9aa5-8cbb-4cde-9352-5422187ea0fa",
   "metadata": {},
   "source": [
    "### Results:\n",
    "For models (NB, NN, XGB, GB, RF), the weights for the top 5 ROC_AUC combination scores:\n",
    "- Weight Combination: (1, 0, 3, 0, 0), ROC_AUC: 0.8870132972370411\n",
    "- Weight Combination: (2, 0, 3, 0, 1), ROC_AUC: 0.8839875786288717\n",
    "- Weight Combination: (3, 1, 2, 1, 1), ROC_AUC: 0.8815689943466838\n",
    "- Weight Combination: (3, 0, 2, 3, 0), ROC_AUC: 0.8802850545425591\n",
    "- Weight Combination: (3, 0, 3, 1, 2), ROC_AUC: 0.8795286248905169\n",
    "\n",
    "After testing all of these results, it appears that the first weight combination produces the best recall for the under-represented class, while also minimizing the False Positives to a reasonable level.  Below is our model build with these weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8be9386-1cc5-48d5-b41b-0ce862879bd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build a VotingClassifier with custom weights\n",
    "custom_weights = [1, 0, 3, 0.25, 0.25]  #classifier_weights\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('nb', nb_model_mod), \n",
    "                ('nn', nn_model_mod), \n",
    "                ('xgb', xgb_model_mod), \n",
    "                ('gb', gb_model_mod),\n",
    "                ('rf', rf_model_mod)],\n",
    "    voting='soft',  \n",
    "    weights=custom_weights\n",
    ")\n",
    "\n",
    "# Fit the ensemble model on the training data\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "ensemble_predictions = ensemble_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c2884ee-be25-46b0-8e0d-5ed5c7be5ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9678111587982833\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1322\n",
      "           1       0.68      0.76      0.72        76\n",
      "\n",
      "    accuracy                           0.97      1398\n",
      "   macro avg       0.83      0.87      0.85      1398\n",
      "weighted avg       0.97      0.97      0.97      1398\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1295   27]\n",
      " [  18   58]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "classification_rep = classification_report(y_test, ensemble_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, ensemble_predictions)\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print('Confusion Matrix:\\n', conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a89b6c-c8f2-4117-99da-a166ca0b7872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8ba650a-35c3-4a8f-b40e-0970ab071b6d",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "351a9ed8-55fa-404f-abd8-c8b917ce68a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save this model\n",
    "save_model(ensemble_model, file_path='models/voting_classifier_best_model2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad645e13-efc6-47c4-9a74-820c07d0ee0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
