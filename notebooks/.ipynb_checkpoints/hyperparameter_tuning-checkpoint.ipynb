{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2292ce52-7329-476a-8870-f2815d6aca62",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9d6923-bffc-4d33-beb3-0e9659112a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d08b170-61d6-4224-a2b3-abb340fec743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from src.hyperparameter_tuning import tune_hyperparameters\n",
    "from src.model_training import build_preprocessor, build_full_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfbfa370-dbc5-4830-9f30-9e0cf86f3ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ... (Read data, df_construct, and other necessary steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54c0b569-c3ef-4465-a3fb-9db4faa06a10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use this code in the event that it's needed\n",
    "df = pd.read_csv('data/processed_data/df_cleaned.csv')\n",
    "X = df.drop('at_risk', axis=1)\n",
    "y = df.at_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8158d119-aec9-4836-b0d3-ff1150b23d44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c044176f-bb9b-46a8-81fa-333ddaea0687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1d0eb-76fd-4153-b3e1-b52f51014335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba84552-fc35-41a1-8497-c05130f07d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbece9b2-0b83-42d7-94bb-3365ae3b47d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd18e7-2e5c-4f69-96ce-2ba0ffbe3143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c2cc76e-897d-476e-83af-77f3179bffa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "preprocessor = build_preprocessor(numeric_features, categorical_features)\n",
    "model = RandomForestClassifier()\n",
    "full_pipeline = build_full_pipeline(preprocessor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3169cf5-d2fa-48c6-93c0-885c527071d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search = tune_hyperparameters(full_pipeline, {}, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e8a142d-80ce-4d60-8e90-768ca001fc1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Models:\n",
      "  params  mean_test_score  std_test_score\n",
      "0     {}         0.940868        0.015465\n",
      "\n",
      "Best Model Accuracy: 0.9635193133047211\n",
      "Best Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1322\n",
      "           1       0.93      0.36      0.51        76\n",
      "\n",
      "    accuracy                           0.96      1398\n",
      "   macro avg       0.95      0.68      0.75      1398\n",
      "weighted avg       0.96      0.96      0.96      1398\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1320    2]\n",
      " [  49   27]]\n"
     ]
    }
   ],
   "source": [
    "# Analyze grid search results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# Display the top models based on mean test scores\n",
    "top_models = cv_results.sort_values(by='mean_test_score', ascending=False).head()\n",
    "print(\"Top Models:\")\n",
    "print(top_models[['params', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "# Select the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report for the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "classification_rep_best = classification_report(y_test, y_pred_best)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "print(f\"\\nBest Model Accuracy: {accuracy_best}\")\n",
    "print(\"Best Model Classification Report:\\n\", classification_rep_best)\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "901680d8-8b4a-48c0-b52a-7005bc922e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__class_weight': None,\n",
       " 'model__max_depth': None,\n",
       " 'model__max_features': 'sqrt',\n",
       " 'model__min_samples_leaf': 1,\n",
       " 'model__min_samples_split': 5,\n",
       " 'model__n_estimators': 300}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_models['params'][54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c86eab-37c2-498e-ba07-f0dbee5f44f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hyperparameter_tuning import tune_hyperparameters\n",
    "\n",
    "# Example for RandomForestClassifier\n",
    "rf_pipeline = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
    "rf_param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [30, 50, 100, 200, 300],\n",
    "    'randomforestclassifier__max_depth': [None, 2, 3, 5, 10, 20, 30],\n",
    "    'randomforestclassifier__class_weight': [None, 'balanced'],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10],\n",
    "    'randomforestclassifier__min_samples_leaf': [1, 2, 4],\n",
    "    'randomforestclassifier__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "rf_grid_search = tune_hyperparameters(rf_pipeline, rf_param_grid, X_train, y_train)\n",
    "\n",
    "# Example for GradientBoostingClassifier\n",
    "gb_pipeline = make_pipeline(StandardScaler(), GradientBoostingClassifier())\n",
    "gb_param_grid = {\n",
    "    'gradientboostingclassifier__n_estimators': [50, 100, 200],\n",
    "    'gradientboostingclassifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'gradientboostingclassifier__max_depth': [3, 5, 7],\n",
    "    'gradientboostingclassifier__min_samples_split': [2, 5, 10],\n",
    "    'gradientboostingclassifier__min_samples_leaf': [1, 2, 4],\n",
    "    'gradientboostingclassifier__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "gb_grid_search = tune_hyperparameters(gb_pipeline, gb_param_grid, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546bcf9-9a82-4145-90fb-e0c3e3772199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f4504-c93e-49b8-9398-5f316a99dc13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac995b6a-a202-43e8-bb0d-2c9dc30c3db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9aef6c-6126-475f-bda1-610538a61d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda9978-f7f7-477d-a087-f2aa02fa7ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eedc5409-48f2-444a-be6d-0ab2aee7b786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "numeric_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "preprocessor = build_preprocessor(numeric_features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a6e6a2f-3626-448b-98fa-3c8e6975a190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_model = build_full_pipeline(preprocessor,GaussianNB())\n",
    "nn_model = build_full_pipeline(preprocessor,MLPClassifier())\n",
    "xgb_model = build_full_pipeline(preprocessor,XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46af2d8c-1a1e-4c79-a842-55d225702321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [3, 5, 7],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'model__scale_pos_weight': [1, 3, 5]  # Adjust based on the class imbalance\n",
    "}\n",
    "\n",
    "# Hyperparameter grid for Gaussian Naive Bayes\n",
    "nb_param_grid = {\n",
    "    'model__priors': [None, [0.1, 0.9], [0.5, 0.5], [0.9, 0.1]]\n",
    "}\n",
    "\n",
    "nn_param_grid = {\n",
    "    'model__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "    'model__activation': ['relu', 'tanh'],\n",
    "    'model__alpha': [0.0001, 0.001, 0.01],\n",
    "    'model__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'model__solver': ['sgd', 'adam'],\n",
    "    'model__max_iter': [200, 400, 600],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736eb0e-32b6-4168-bad6-29cb802793c5",
   "metadata": {},
   "source": [
    "## XGB Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "021eb7ae-8675-4b10-90ac-53c2edf3da1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost hyperparameters: {'model__learning_rate': 0.1, 'model__max_depth': 5, 'model__n_estimators': 100, 'model__scale_pos_weight': 3}\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters\n",
    "tuned_xgb_model = tune_hyperparameters(xgb_model, xgb_param_grid, X_train, y_train)\n",
    "\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_xgb_params = tuned_xgb_model.best_params_\n",
    "\n",
    "\n",
    "# Print or use the best hyperparameters as needed\n",
    "print(\"Best XGBoost hyperparameters:\", best_xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bc3c57d-2483-4b69-94b2-62df647d784e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Models:\n",
      "                                               params  mean_test_score  \\\n",
      "40  {'model__learning_rate': 0.1, 'model__max_dept...         0.937401   \n",
      "37  {'model__learning_rate': 0.1, 'model__max_dept...         0.935185   \n",
      "38  {'model__learning_rate': 0.1, 'model__max_dept...         0.934876   \n",
      "35  {'model__learning_rate': 0.1, 'model__max_dept...         0.933457   \n",
      "41  {'model__learning_rate': 0.1, 'model__max_dept...         0.933407   \n",
      "\n",
      "    std_test_score  \n",
      "40        0.020689  \n",
      "37        0.021410  \n",
      "38        0.020055  \n",
      "35        0.024558  \n",
      "41        0.020956  \n",
      "\n",
      "Best Model Accuracy: 0.9699570815450643\n",
      "Best Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1322\n",
      "           1       0.76      0.66      0.70        76\n",
      "\n",
      "    accuracy                           0.97      1398\n",
      "   macro avg       0.87      0.82      0.84      1398\n",
      "weighted avg       0.97      0.97      0.97      1398\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1306   16]\n",
      " [  26   50]]\n"
     ]
    }
   ],
   "source": [
    "# Analyze grid search results\n",
    "cv_results = pd.DataFrame(tuned_xgb_model.cv_results_)\n",
    "\n",
    "# Display the top models based on mean test scores\n",
    "top_models = cv_results.sort_values(by='mean_test_score', ascending=False).head()\n",
    "print(\"Top Models:\")\n",
    "print(top_models[['params', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "# Select the best model\n",
    "best_model = tuned_xgb_model.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report for the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "classification_rep_best = classification_report(y_test, y_pred_best)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "print(f\"\\nBest Model Accuracy: {accuracy_best}\")\n",
    "print(\"Best Model Classification Report:\\n\", classification_rep_best)\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c5766-792d-499d-8d52-6d33d3ba566e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Observations:\n",
    "- Compared to the base XGBoost performance seen in the model_training_notebook, we do have some improvement to the recall score of the under-represented class.  It does come at the cost of a slight increase in false positives, but worth the nearly 8% increase in recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56641e7-2614-41f9-9200-d8f3af6cf818",
   "metadata": {},
   "source": [
    "## Naive Bayes Tuning\n",
    "- There is not much tuning to do for NB, but we'll make some changes to the \"priors\" parameter to see if we can come up with even a slightly improved model from the one before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31cbd628-6a00-44b0-a111-edf38475ed4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Naive Bayes hyperparameters: {'model__priors': None}\n"
     ]
    }
   ],
   "source": [
    "# Tune hyperparameters\n",
    "tuned_nb_model = tune_hyperparameters(nb_model, nb_param_grid, X_train, y_train)\n",
    "\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_nb_params = tuned_nb_model.best_params_\n",
    "\n",
    "\n",
    "# Print or use the best hyperparameters as needed\n",
    "print(\"Best Naive Bayes hyperparameters:\", best_nb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bae6b6d8-376c-475d-8d84-d83f6bb10c1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Models:\n",
      "                          params  mean_test_score  std_test_score\n",
      "0        {'model__priors': None}         0.738422        0.026415\n",
      "1  {'model__priors': [0.1, 0.9]}         0.738422        0.026415\n",
      "2  {'model__priors': [0.5, 0.5]}         0.738422        0.026415\n",
      "3  {'model__priors': [0.9, 0.1]}         0.738422        0.026415\n",
      "\n",
      "Best Model Accuracy: 0.6609442060085837\n",
      "Best Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.65      0.78      1322\n",
      "           1       0.11      0.78      0.20        76\n",
      "\n",
      "    accuracy                           0.66      1398\n",
      "   macro avg       0.55      0.72      0.49      1398\n",
      "weighted avg       0.93      0.66      0.75      1398\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[865 457]\n",
      " [ 17  59]]\n"
     ]
    }
   ],
   "source": [
    "# Analyze grid search results\n",
    "cv_results = pd.DataFrame(tuned_nb_model.cv_results_)\n",
    "\n",
    "# Display the top models based on mean test scores\n",
    "top_models = cv_results.sort_values(by='mean_test_score', ascending=False).head()\n",
    "print(\"Top Models:\")\n",
    "print(top_models[['params', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "# Select the best model\n",
    "best_model = tuned_nb_model.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report for the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "classification_rep_best = classification_report(y_test, y_pred_best)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "print(f\"\\nBest Model Accuracy: {accuracy_best}\")\n",
    "print(\"Best Model Classification Report:\\n\", classification_rep_best)\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d8ffc9-cbac-4288-bd46-e4b3c0bdc1ac",
   "metadata": {},
   "source": [
    "### Obeservations:\n",
    "- This model is no better than the one we had previously in that, it contains more false negatives.  Despite the fact that the NB model does have a substantially low accuracy (with many false positives), we used it in the ensemble meta model because of it's high recall rate for the under-represented class.\n",
    "- When we retrain the ensemble model, we will stick with the out-of-the-box NB model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e00979-bacd-4f7a-ae3a-246c58bff5ab",
   "metadata": {},
   "source": [
    "## Neural Network Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8f817a-9228-41f3-a659-4f71bf28beb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tune hyperparameters\n",
    "tuned_nn_model = tune_hyperparameters(nn_model, nn_param_grid, X_train, y_train)\n",
    "\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_nn_params = tuned_nn_model.best_params_\n",
    "\n",
    "\n",
    "# Print or use the best hyperparameters as needed\n",
    "print(\"Best Neural Net hyperparameters:\", best_nn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234149ce-3ead-4bda-9730-9e388e831436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze grid search results\n",
    "cv_results = pd.DataFrame(tuned_nn_model.cv_results_)\n",
    "\n",
    "# Display the top models based on mean test scores\n",
    "top_models = cv_results.sort_values(by='mean_test_score', ascending=False).head()\n",
    "print(\"Top Models:\")\n",
    "print(top_models[['params', 'mean_test_score', 'std_test_score']])\n",
    "\n",
    "# Select the best model\n",
    "best_model = tuned_nn_model.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report for the best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "classification_rep_best = classification_report(y_test, y_pred_best)\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "print(f\"\\nBest Model Accuracy: {accuracy_best}\")\n",
    "print(\"Best Model Classification Report:\\n\", classification_rep_best)\n",
    "print('\\nConfusion Matrix:\\n', conf_matrix_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
